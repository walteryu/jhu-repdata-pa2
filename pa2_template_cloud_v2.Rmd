---
title: "Reproducible Research: Peer Assessment 2"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Title: JHU-DSCI Reproducible Research
## Peer Assessment 2: NOAA Storm Data

### Name: Walter Yu
### Date: July 2020

## Synopsis

This document completes an initial analysis of the NOAA Storm Data set as follows: 

1. Download and read the raw NOAA storm dataset 
2. Review and clean data before analysis 
3. Analyze data to answer assignment questions 
4. Plot data to communicate results 
5. Document steps and findings to be reproducible

## Submission Notes

1. This markdown file is an analysis and visualization of the NOAA weather dataset. Source data available [here][1].

[1]: https://d396qusza40orc.cloudfront.net/repdata%2Fdata%2FStormData.csv.bz2

2. The document for this assignment was generated with [R Studio Cloud][2] due to package installation errors on my local machine; as a result, file was run and report rendered there instead.

[2]: https://rstudio.cloud

This markdown project template is based on a fork of the course assignment Github repo available [here][3].

[3]: https://github.com/rdpeng/RepData_PeerAssessment1

This assignment is completed for the JHU Coursera Data Science Program, which is a 10-course certification. More info about this program is available [here][4].

[4]: https://www.coursera.org/specializations/jhu-data-science

## Questions

1. Across the United States, which types of events (as indicated in the EVTYPE variable) are most harmful with respect to population health?

2. Across the United States, which types of events have the greatest economic consequences?

## Part 1: Data Processing

### Part 1A: Data Import

Steps:

1. Initially attempted to load data from url
2. However, attempts resulted in error so loaded from bz2 zipfile instead
3. From there, file was unzipped and read into program
4. Data import step is saved as its own chunk and [cached][1a_cache]

[1a_cache]: https://bookdown.org/yihui/rmarkdown-cookbook/cache.html

### Part 1B: Data Clean

Steps:

1. Used na.omit function to remove null values
2. However, na.omit removed most values do not used on dataset

Analysis:

1. There are 37 variables, only some of which are needed for analysis
2. NOAA documentation quantifies health impacts with fatailities/injuries 
3. So, aggregate fatailities/injuries by event type

```{r echo=TRUE}

# part 1a: data import read from csv.bz2 format

# source: https://rpubs.com/otienodominic/398952
# note: unsuccessful after several attempts, so revert to reading from bz2 file
# url <- "https://d396qusza40orc.cloudfront.net/repdata%2Fdata%2FStormData.csv.bz2"
# temp <- tempfile()
# download.file(url, temp, mode="wb")
# data <- read.csv("repdata_data_StormData.csv.bz2", header=TRUE, sep=",")
# unlink(zipfile)

# source: assignment instructions
# https://www.coursera.org/learn/reproducible-research/discussions/weeks/4/threads/38y35MMiEeiERhLphT2-QA
data <- read.csv("data/repdata_data_StormData.csv.bz2")

```

```{r echo=TRUE}

# part 1b: data processing - review data

# note: course discussion forum consulted for these steps:
# https://www.coursera.org/learn/reproducible-research/discussions/weeks/4/threads/38y35MMiEeiERhLphT2-QA

# review dataset
# conclusion: dataset contains many columns, only some of which seem to be useful
# https://www.statmethods.net/stats/descriptives.html
# head(data)
# names(data)
# summary(data)

# attempt remove null values
# source: https://www.statmethods.net/input/missingdata.html
# data_omit <- na.omit(data)

# verify results
# conclusion: na.omit removes most records, so not used on dataset
# https://www.statmethods.net/stats/descriptives.html
# head(data_omit)
# names(data_omit)
# summary(data_omit)

# identify event types
# conclusion: results show a large number of event types
# unique(data$EVTYPE)

# todo: agrepl usage
# https://www.coursera.org/learn/reproducible-research/discussions/weeks/4/threads/XdHXZccTEemRWg4GTNs16g

```

```{r echo=TRUE}

# part 1b: data processing - analyze event types by fatalities

# aggregate by fatality or injury, then apply calculations
# source: https://www.statmethods.net/management/aggregate.html
event_fatal_total <- aggregate(FATALITIES ~ EVTYPE, data, sum)

# rank aggregate results:
# https://stackoverflow.com/questions/23659241/rank-in-the-aggregate-function
event_fatal_total <- event_fatal_total[order(event_fatal_total$FATALITIES, decreasing=TRUE),]

# subset for top 50 event types with highest count
# https://stackoverflow.com/questions/2667673/select-first-4-rows-of-a-data-frame-in-r/47400307
event_fatal_50 <- event_fatal_total[1:50,]
# event_fatal_50

# ratio of fatalities due to top 50 event types / all event types
event_fatal_50_sum <- sum(event_fatal_50$FATALITIES)
event_fatal_total_sum <- sum(event_fatal_total$FATALITIES)
event_fatal_ratio <- event_fatal_50_sum / event_fatal_total_sum
print("ratio of fatalities from top 50 / all event types:")
print(event_fatal_ratio)

# note: based on results above, storm-related and heat have highest totals 
# conclusion: calculate ratios for these events to create plots
event_fatal_8 <- event_fatal_total[1:8,]
event_fatal_8

```

```{r echo=TRUE}

# part 1b: data processing - analyze event types by injuries

# aggregate by fatality or injury, then apply calculations
# source: https://www.statmethods.net/management/aggregate.html
event_injury_total <- aggregate(INJURIES ~ EVTYPE, data, sum)

# rank aggregate results:
# https://stackoverflow.com/questions/23659241/rank-in-the-aggregate-function
event_injury_total <- event_injury_total[order(event_injury_total$INJURIES, decreasing=TRUE),]

# subset for top 50 event types with highest count
# https://stackoverflow.com/questions/2667673/select-first-4-rows-of-a-data-frame-in-r/47400307
event_injury_50 <- event_injury_total[1:50,]
# event_injury_50

# ratio of injuryities due to top 50 event types / all event types
event_injury_50_sum <- sum(event_injury_50$INJURIES)
event_injury_total_sum <- sum(event_injury_total$INJURIES)
event_injury_ratio <- event_injury_50_sum / event_injury_total_sum
print("ratio of injuries from top 50 / all event types:")
print(event_injury_ratio)

# note: based on results above, storm-related and heat have highest totals 
# conclusion: calculate ratios for these events to create plots
event_injury_6 <- event_injury_total[1:6,]
event_injury_6

```

```{r echo=TRUE}

# part 1b: data processing - plot event types by fatalities

# note: based on results above, storm-related and heat have highest totals 
# conclusion: calculate ratios for these events to create plots
# http://www.sthda.com/english/wiki/ggplot2-barplots-quick-start-guide-r-software-and-data-visualization
# https://stackoverflow.com/questions/16961921/plot-data-in-descending-order-as-appears-in-data-frame
# install.packages("ggplot2")
# library(ggplot2)
p_fatal <- ggplot(data=event_fatal_8, aes(x=reorder(EVTYPE, -FATALITIES), y=FATALITIES, fill=EVTYPE)) + geom_bar(stat="identity")
p_fatal + coord_flip()

```

```{r echo=TRUE}

# part 1b: data processing - plot event types by injuries

# note: based on results above, storm-related and heat have highest totals 
# conclusion: calculate ratios for these events to create plots
# http://www.sthda.com/english/wiki/ggplot2-barplots-quick-start-guide-r-software-and-data-visualization
# https://stackoverflow.com/questions/16961921/plot-data-in-descending-order-as-appears-in-data-frame
# install.packages("ggplot2")
# library(ggplot2)
p_injury <- ggplot(data=event_injury_6, aes(x=reorder(EVTYPE, -INJURIES), y=INJURIES, fill=EVTYPE)) + geom_bar(stat="identity")
p_injury + coord_flip()

```

```{r echo=TRUE}

# part 1b: data processing - analyze event types by economic impact
# note: analyze property damage per course discussion post 
# https://www.coursera.org/learn/reproducible-research/discussions/weeks/4/threads/38y35MMiEeiERhLphT2-QA
names(data)
summary(data$PROPDMG)
summary(data$PROPDMGEXP)
summary(data$CROPDMG)
summary(data$CROPDMGEXP)

```

```{r echo=TRUE}

# part 1b: data processing - analyze event types by property damage exp.

# *** note: sources for code below ***
# subset and verify results:
# https://stats.idre.ucla.edu/r/faq/frequently-asked-questions-about-rhow-can-i-subset-a-data-setthe-r-program-as-a-text-file-for-all-the-code-on-this-page-subsetting-is-a-very-important-component/
# subset and verify results:
# https://stats.idre.ucla.edu/r/faq/frequently-asked-questions-about-rhow-can-i-subset-a-data-setthe-r-program-as-a-text-file-for-all-the-code-on-this-page-subsetting-is-a-very-important-component/
# convert powers of 10:
# https://en.wikipedia.org/wiki/Exponentiation#Powers_of_ten

# note: please refer to cited code sources above
prop_0e_subset <- subset(data, PROPDMGEXP == 1, select = c(EVTYPE, PROPDMG, PROPDMGEXP, PROPDMGTOT))
prop_0e_subset
prop_0e_subset$PROPDMGTOT <- with(prop_0e_subset, ifelse(PROPDMGEXP == 1, PROPDMG*0, "NA"))
prop_0e_subset

# note: please refer to cited code sources above
prop_1e_subset <- subset(data, PROPDMGEXP == 0, select = c(EVTYPE, PROPDMG, PROPDMGEXP, PROPDMGTOT))
prop_1e_subset
prop_1e_subset$PROPDMGTOT <- with(prop_1e_subset, ifelse(PROPDMGEXP == 0, PROPDMG*10, "NA"))
prop_1e_subset

# note: please refer to cited code sources above
prop_2e_subset <- subset(data, PROPDMGEXP == 2, select = c(EVTYPE, PROPDMG, PROPDMGEXP, PROPDMGTOT))
prop_2e_subset
prop_2e_subset$PROPDMGTOT <- with(prop_2e_subset, ifelse(PROPDMGEXP == 2, PROPDMG*10^2, "NA"))
prop_2e_subset

# note: please refer to cited code sources above
prop_3e_subset <- subset(data, PROPDMGEXP == 3 | PROPDMGEXP == "K", select = c(EVTYPE, PROPDMG, PROPDMGEXP, PROPDMGTOT))
prop_3e_subset
prop_3e_subset$PROPDMGTOT <- with(prop_3e_subset, ifelse(PROPDMGEXP == 3 | PROPDMGEXP == "K", PROPDMG*10^3, "NA"))
prop_3e_subset

# note: please refer to cited code sources above
prop_4e_subset <- subset(data, PROPDMGEXP == 4, select = c(EVTYPE, PROPDMG, PROPDMGEXP, PROPDMGTOT))
prop_4e_subset
prop_4e_subset$PROPDMGTOT <- with(prop_4e_subset, ifelse(PROPDMGEXP == 4, PROPDMG*10^4, "NA"))
prop_4e_subset

# note: please refer to cited code sources above
prop_5e_subset <- subset(data, PROPDMGEXP == 5, select = c(EVTYPE, PROPDMG, PROPDMGEXP, PROPDMGTOT))
prop_5e_subset
prop_5e_subset$PROPDMGTOT <- with(prop_5e_subset, ifelse(PROPDMGEXP == 5, PROPDMG*10^5, "NA"))
prop_5e_subset

# note: please refer to cited code sources above
prop_6e_subset <- subset(data, PROPDMGEXP == 6 | PROPDMGEXP == "M", select = c(EVTYPE, PROPDMG, PROPDMGEXP, PROPDMGTOT))
prop_6e_subset
prop_6e_subset$PROPDMGTOT <- with(prop_6e_subset, ifelse(PROPDMGEXP == 6 | PROPDMGEXP == "M", PROPDMG*10^6, "NA"))
prop_6e_subset

# note: please refer to cited code sources above
prop_7e_subset <- subset(data, PROPDMGEXP == 7, select = c(EVTYPE, PROPDMG, PROPDMGEXP, PROPDMGTOT))
prop_7e_subset
prop_7e_subset$PROPDMGTOT <- with(prop_7e_subset, ifelse(PROPDMGEXP == 7, PROPDMG*10^7, "NA"))
prop_7e_subset

# note: please refer to cited code sources above
prop_8e_subset <- subset(data, PROPDMGEXP == 8, select = c(EVTYPE, PROPDMG, PROPDMGEXP, PROPDMGTOT))
prop_8e_subset
prop_8e_subset$PROPDMGTOT <- with(prop_8e_subset, ifelse(PROPDMGEXP == 8, PROPDMG*10^8, "NA"))
prop_8e_subset

# note: please refer to cited code sources above
prop_9e_subset <- subset(data, PROPDMGEXP == "B", select = c(EVTYPE, PROPDMG, PROPDMGEXP, PROPDMGTOT))
prop_9e_subset
prop_9e_subset$PROPDMGTOT <- with(prop_9e_subset, ifelse(PROPDMGEXP == "B", PROPDMG*10^9, "NA"))
prop_9e_subset

propdmgtot_subset <- rbind(prop_0e_subset, prop_1e_subset)
propdmgtot_subset

# aggregate by cropdmg or propdmg, then apply calculations
# source: https://www.statmethods.net/management/aggregate.html
event_propdmg_total <- aggregate(PROPDMGEXP ~ EVTYPE, data, FUN=length)

# rank aggregate results:
# https://stackoverflow.com/questions/23659241/rank-in-the-aggregate-function
event_propdmg_total <- event_propdmg_total[order(event_propdmg_total$PROPDMGEXP, decreasing=TRUE),]

# subset for top 50 event types with highest count
# https://stackoverflow.com/questions/2667673/select-first-4-rows-of-a-data-frame-in-r/47400307
event_propdmg_50 <- event_propdmg_total[1:50,]
# event_propdmg_50

# ratio of propdmgities due to top 50 event types / all event types
event_propdmg_50_sum <- sum(event_propdmg_50$PROPDMGEXP)
event_propdmg_total_sum <- sum(event_propdmg_total$PROPDMGEXP)
event_propdmg_ratio <- event_propdmg_50_sum / event_propdmg_total_sum
print("ratio of property damage exp. from top 50 / all event types:")
print(event_propdmg_ratio)

# note: based on results above, storm-related and heat have highest totals 
# conclusion: calculate ratios for these events to create plots
event_propdmg_10 <- event_propdmg_total[1:10,]
event_propdmg_10

```

```{r echo=TRUE}

# part 1b: data processing - analyze event types by crop damage

# aggregate by propdmg or cropdmg, then apply calculations
# source: https://www.statmethods.net/management/aggregate.html
event_cropdmg_total <- aggregate(INJURIES ~ EVTYPE, data, sum)

# rank aggregate results:
# https://stackoverflow.com/questions/23659241/rank-in-the-aggregate-function
event_cropdmg_total <- event_cropdmg_total[order(event_cropdmg_total$INJURIES, decreasing=TRUE),]

# subset for top 50 event types with highest count
# https://stackoverflow.com/questions/2667673/select-first-4-rows-of-a-data-frame-in-r/47400307
event_cropdmg_50 <- event_cropdmg_total[1:50,]
# event_cropdmg_50

# ratio of cropdmgities due to top 50 event types / all event types
event_cropdmg_50_sum <- sum(event_cropdmg_50$INJURIES)
event_cropdmg_total_sum <- sum(event_cropdmg_total$INJURIES)
event_cropdmg_ratio <- event_cropdmg_50_sum / event_cropdmg_total_sum
print("ratio of injuries from top 50 / all event types:")
print(event_cropdmg_ratio)

# note: based on results above, storm-related and heat have highest totals 
# conclusion: calculate ratios for these events to create plots
event_cropdmg_5 <- event_cropdmg_total[1:6,]
event_cropdmg_5

```